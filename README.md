# ğŸ“± Mobile Health App Review Analysis

---

## ğŸ† Results at a Glance

| Metric | Value |
|--------|-------|
| ğŸ¯ ML Accuracy (CV) | **95.61%** |
| ğŸ“Š Test Set Accuracy | **92.86%** |
| ğŸ“± Apps Analyzed | **137 unique apps** |
| ğŸ”¬ Mean SUS Score | **85.4 / 100** |
| ğŸ©º Clinician Promoters | **43.8%** |
| ğŸ¤– Best Model | **Soft-Voting Ensemble** |

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ MobileHealthApp_Hackathon.ipynb   # Main analysis notebook
â”œâ”€â”€ mobile_health_app_review_data.csv # Dataset
â”œâ”€â”€ README.md                         # You are here
â””â”€â”€ outputs/
    â”œâ”€â”€ shap_importance_by_class.png
    â”œâ”€â”€ shap_beeswarm_excellent.png
    â”œâ”€â”€ shap_bar_all_classes.png
    â”œâ”€â”€ shap_waterfall.png
    â””â”€â”€ shap_dependence.png
```

---

## ğŸ“– Project Overview

This project analyzes **274 reviews** of mobile health apps collected from both **clinician** and **non-clinician** reviewers. The dataset captures a dual-reviewer structure where:

- `clinician_reviewer` â€” fills the **NPS-style Recommendation Score** (0â€“10)
- `nonclinician_reviewer` â€” fills all **10 SUS (System Usability Scale)** items (1â€“5 Likert)

The goal is to uncover usability trends, compliance gaps, and engagement patterns â€” and build a machine learning model that predicts usability grades with **â‰¥95% accuracy**.

---

## ğŸ—‚ï¸ Dataset Description

| Column Group | Description |
|---|---|
| `AppID`, `AppName` | App identifier and name |
| `Reviewer`, `Platform`, `OS` | Review metadata |
| `SUS Items (Q1â€“Q10)` | 10 Likert-scale usability questions |
| `Recommendation Score` | 0â€“10 NPS-style clinician score |
| `Binary Feature Flags` | Privacy policy, login, ads, device sync, etc. |
| `Developer Info` | Developer type (for-profit, gov, academic, etc.) |
| `App Store Ratings` | iOS/Android avg ratings and download counts |

---

## ğŸ§¹ Data Preprocessing

- **Dual-reviewer structure** identified and handled separately
- **Likert parser** converts mixed strings like `"5 (Strongly agree)"` â†’ `5.0`
- **SUS Score** computed using the standard formula:
  - Odd items `(Q1,3,5,7,9)`: contribution = `score âˆ’ 1`
  - Even items `(Q2,4,6,8,10)`: contribution = `5 âˆ’ score`
  - Final score = `sum Ã— 2.5` â†’ range **[0, 100]**
- **Binary encoding** for all Yes/No compliance features
- **Median imputation** for any remaining missing SUS values

---

## ğŸ“Š Exploratory Data Analysis

The notebook contains **9 visualizations** covering:

1. ğŸ“ˆ SUS Score distribution with grade thresholds
2. ğŸ”¢ Item-level mean scores + correlation heatmap
3. ğŸ—³ï¸ Clinician recommendation score distribution
4. ğŸ“‹ Feature adoption/compliance rates across all apps
5. ğŸ¥§ Developer type breakdown
6. ğŸ“¦ SUS boxplots by key features (privacy policy, device sync, etc.)
7. ğŸ–¥ï¸ Platform & OS impact on usability
8. ğŸ‘¥ Patient engagement modalities
9. ğŸ¢ SUS vs clinical expert involvement

### Key EDA Findings

- ğŸ“Œ Mean SUS of **85.4** â€” well above the industry benchmark of **68**
- ğŸ“Œ Only **54%** of apps have a privacy policy
- ğŸ“Œ Only **36%** involve clinical experts in development
- ğŸ“Œ Only **7%** claim HIPAA compliance
- ğŸ“Œ Only **13%** sync with wearable/peripheral devices
- ğŸ“Œ Only **20%** reward users for engagement

---

## ğŸ¤– Machine Learning

### Target Variable
**SUS Usability Grade** (3-class classification):

| Class | Grade | SUS Range |
|-------|-------|-----------|
| 0 | Poor / Marginal | < 75 |
| 1 | Good | 75 â€“ 89 |
| 2 | Excellent | â‰¥ 90 |

### Feature Engineering

On top of the raw SUS items and binary flags, these engineered features were created:

| Feature | Formula |
|---|---|
| `pos_subscale` | Sum of Q1+Q3+Q5+Q7+Q9 |
| `neg_subscale` | Sum of Q2+Q4+Q6+Q8+Q10 |
| `pos_neg_ratio` | `pos / (neg + 0.001)` |
| `ease_cluster` | Q3 + Q7 + Q9 |
| `complexity_cluster` | Q2 + Q4 + Q8 |
| `consistency_score` | Q5 âˆ’ Q6 |
| `compliance_score` | Sum of all binary feature flags |

### Models Evaluated

| Model | CV Accuracy |
|-------|------------|
| Logistic Regression | ~72% |
| Gradient Boosting | ~91% |
| Random Forest | ~95% |
| Extra Trees | ~94% |
| XGBoost *(if installed)* | ~95% |
| LightGBM *(if installed)* | ~95% |
| **Ensemble (Soft Vote)** | **95.61% âœ…** |

> 5-Fold Stratified Cross-Validation used throughout.

---

## ğŸ” Explainable AI â€” SHAP Analysis

The notebook includes a full **SHAP (SHapley Additive exPlanations)** analysis with 5 plots:

| Plot | Description |
|------|-------------|
| **Mean \|SHAP\| by class** | Top features driving each usability grade |
| **Beeswarm plot** | How feature values push predictions for "Excellent" class |
| **Stacked bar** | Combined importance across all 3 classes |
| **Waterfall plot** | Step-by-step explanation for one individual app |
| **Dependence plots** | How the top 2 features interact with SHAP values |

### Top SHAP Drivers
- `âŠ• Positive Subscale` â€” single strongest predictor
- `Ease Cluster (Q3+Q7+Q9)` â€” confidence + learnability
- `âŠ•/âŠ– Ratio` â€” balance of positive vs negative responses
- `Complexity Cluster` â€” negatively impacts Excellent class
- `Q9: Felt Confident` â€” high individual importance

---

## ğŸš€ How to Run

### Option 1 â€” Google Colab *(recommended)*

1. Open [Google Colab](https://colab.research.google.com)
2. Upload `MobileHealthApp_Hackathon.ipynb`
3. Upload `mobile_health_app_review_data.csv` to the Colab session
4. Run all cells top to bottom

### Option 2 â€” Local

```bash
git clone https://github.com/Sundaram04/Innofusion_hackathon.git
cd Innofusion
pip install pandas numpy matplotlib seaborn scikit-learn shap xgboost lightgbm
jupyter notebook MobileHealthApp_Hackathon.ipynb
```

---

## ğŸ“¦ Dependencies

```
pandas
numpy
matplotlib
seaborn
scikit-learn
shap
xgboost        # optional but recommended
lightgbm       # optional but recommended
jupyter
```

---

## ğŸ’¡ Key Recommendations

Based on EDA and SHAP findings, the top actions for app developers are:

- ğŸ” **Add a privacy policy** â€” missing in 46% of apps, directly impacts user trust
- ğŸ‘¨â€âš•ï¸ **Involve clinical experts** in development and QA (only 36% do)
- ğŸ® **Add reward/gamification systems** â€” only 20% of apps currently do this
- ğŸ”” **Build safety alerts** for dangerous health data inputs (only 17% do)
- ğŸ“² **Integrate with wearables** â€” a major gap, only 13% support device sync
- ğŸ“‹ **Reference clinical guidelines** â€” boosts clinician recommendation scores
- ğŸ¥ **Pursue HIPAA compliance** â€” currently claimed by only 7% of apps

---

## ğŸ“Œ Notebook Structure

| Section | Content |
|---------|---------|
| 1 | Setup & Imports |
| 2 | Data Loading & Inspection |
| 3 | Cleaning & Preprocessing |
| 4 | Exploratory Data Analysis (9 plots) |
| 5 | ML â€” Feature Engineering |
| 6 | ML â€” Cross-Validation & Model Comparison |
| 7 | ML â€” Ensemble & Final Results |
| 8 | ML â€” Visualizations & Confusion Matrix |
| 9 | Feature Importance (Random Forest) |
| 10 | Explainable AI â€” SHAP Analysis (5 plots) |
| 11 | Bonus: Recommendation Score Prediction |
| 12 | Key Insights & Recommendations |

---

## ğŸ‘¤ Team BLOCKSMITHS

---

## ğŸ“„ License

This project is open source under the [MIT License](LICENSE).
